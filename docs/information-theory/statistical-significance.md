---
title: 信息论:统计显著性
comments: true
---

## 互信息

互信息$I(X; Y)$衡量的是两个变量$X$和$Y$的依赖关系, 如果$I(X;Y)=0$, 意味着$X$和$Y$是独立的, 没有任何信息共享. 这在理论上是正确的, 但是在实际事件中, 对于经验数据来说, 即使$X$和$Y$是独立的, 我们依然可能会观测到$I(X;Y)\neq 0$. 这是因为现实中的数据可能存在噪声或者误差, 从而导致互信息的估计不等于$0$. 

所以, 在现实中, 我们要考虑两个问题:

1. 给定的$I(X;Y)$的估计值与$0$是否有显著差异? 也就是说, 我们是否可以认为观测到的互信息实际上表明了某种依赖性, 而不是由噪声引起的
2. 为了准确地估计$I(X;Y)$, 我们需要多少样本? 即, 需要多少数据点来确定互信息的真实性或者接近真实值

## 统计性检验

对于第一个问题, 可以使用统计方法检验互信息. 设原假设$H_0$为$X$与$Y$独立, 备择假设为$X$与$Y$存在依赖关系. 为了检验$H_0$, 需要估计在假设$H_0$成立的时候, 采样统计量$I(X;Y)$的概率分布, 这可以通过构建替代分布实现, 具体地说, 就是构建替代分布数据$Y^s$, 使得$Y^s$和$X$独立, 但是保留$Y$的统计特性, 形成一个替代的分布.

???+ example "例子"

    假设我们正在研究学生的学习时间$X$和考试成绩$Y$之间的关系, 为了判断学习时间是否和考试成绩相关, 我们可以计算$I(X;Y)$. 原假设$H_0$为学习时间和考试成绩独立, 即$I(X;Y)=0$, 然后构建替代分布, 随机打乱考试成绩$Y$的顺序, 生成一组"替代成绩"$Y^s$, 这些成绩保留了原始的分布特性, 但是不再与原来的学习时间$X$相关. 计算打乱后的$I(X;Y^s)$, 重复生成多次替代分布. 将实际计算的互信息$I(X;Y)$和替代分布计算得到的互信息进行比较, 计算$p$值. 如果$I(X;Y)$显著大于替代分布的互信息, 就可以认为学习时间和考试成绩之间存在统计学上的显著依赖关系, 拒绝原假设.